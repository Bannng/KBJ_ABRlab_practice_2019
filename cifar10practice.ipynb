{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar10practice.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KrcK8MxZXOVD","colab_type":"code","colab":{}},"source":["from tensorflow.keras.datasets.cifar10 import load_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AW0xu1nAXfGK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"10a0bbb7-0d89-45dc-8468-1f04eeb18356","executionInfo":{"status":"ok","timestamp":1564973191654,"user_tz":-540,"elapsed":12998,"user":{"displayName":"ByoungJu Kim","photoUrl":"https://lh3.googleusercontent.com/-riBzYG_Z9-0/AAAAAAAAAAI/AAAAAAAAADw/GWO6ne1-UCs/s64/photo.jpg","userId":"00703136417474445941"}}},"source":["(x_train, y_train), (x_test, y_test) = load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 9s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FuNX3USfXw_N","colab_type":"code","outputId":"429cebf2-4102-4c3e-acaf-6174eeb7f9bf","executionInfo":{"status":"ok","timestamp":1564973191658,"user_tz":-540,"elapsed":11925,"user":{"displayName":"ByoungJu Kim","photoUrl":"https://lh3.googleusercontent.com/-riBzYG_Z9-0/AAAAAAAAAAI/AAAAAAAAADw/GWO6ne1-UCs/s64/photo.jpg","userId":"00703136417474445941"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(x_train.shape , y_train.shape)\n","print(x_test.shape, y_test.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(50000, 32, 32, 3) (50000, 1)\n","(10000, 32, 32, 3) (10000, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iznnGC79YbA8","colab_type":"code","outputId":"0d717f57-87e9-4905-d187-d76bcbd88584","executionInfo":{"status":"ok","timestamp":1564979748879,"user_tz":-540,"elapsed":97203,"user":{"displayName":"ByoungJu Kim","photoUrl":"https://lh3.googleusercontent.com/-riBzYG_Z9-0/AAAAAAAAAAI/AAAAAAAAADw/GWO6ne1-UCs/s64/photo.jpg","userId":"00703136417474445941"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","X = tf.placeholder(tf.float32, [None, 32*32*3])\n","Y = tf.placeholder(tf.float32, [None, 10])\n","print(X.shape, Y.shape)\n","\n","W1 = tf.Variable(tf.random_normal([3072,512], stddev=0.01))\n","B1 = tf.Variable(tf.random_normal([512], stddev=0.01))\n","L1 = tf.nn.relu(tf.matmul(X,W1)+B1)\n","print(W1.shape, L1.shape)\n","\n","W2 = tf.Variable(tf.random_normal([512,512], stddev = 0.01))\n","B2 = tf.Variable(tf.random_normal([512], stddev=0.01))\n","L2 = tf.nn.relu(tf.matmul(L1,W2)+B2)\n","print(W2.shape, L2.shape)\n","\n","W3 = tf.Variable(tf.random_normal([512,256], stddev = 0.01))\n","B3 = tf.Variable(tf.random_normal([256], stddev=0.01))\n","L3 = tf.nn.relu(tf.matmul(L2,W3)+B3)\n","print(W3.shape, L3.shape)\n","\n","W4 = tf.Variable(tf.random_normal([256,256], stddev = 0.01))\n","B4 = tf.Variable(tf.random_normal([256], stddev = 0.01))\n","L4 = tf.nn.relu(tf.matmul(L3,W4)+B4)\n","print(W4.shape, L4.shape)\n","\n","W5 = tf.Variable(tf.random_normal([256,10], stddev = 0.01))\n","B5 = tf.Variable(tf.random_normal([10], stddev=0.01))\n","model = tf.matmul(L4, W5)+B5\n","\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n","optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n","\n","init = tf.global_variables_initializer()\n","with tf.Session() as sess:\n","  sess.run(init)\n","  \n","  num_epoch = 100 \n","  batch_size = 2500\n","  total_batch = int(len(x_train)/batch_size)\n","  \n","  for epoch in range(num_epoch):\n","    total_cost = 0\n","    \n","    for i in range(total_batch):\n","      if i == (total_batch-1):\n","        order = list(range(len(x_train)))\n","        import random\n","        random.shuffle(order)\n","        x_train = x_train[order]\n","        y_train = y_train[order]\n","        \n","      batch_xs = x_train[i*batch_size:(i+1)*batch_size].reshape(batch_size, -1)\n","      batch_ys = np.eye(10)[y_train[i*batch_size:(i+1)*batch_size]].reshape(batch_size,-1)\n","      #print(batch_xs.shape)\n","      #print(batch_ys.shape)\n","      \n","      _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})  # keep_prob is 80 percent here\n","      total_cost += cost_val\n","      #print(cost_val)\n","      #print(_)\n","\n","    print('Epoch:', '%04d' % (epoch + 1),\n","          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))   \n","  \n","  print('최적화 완료!')\n","  \n","  is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n","  accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n","  #print('정확도:', sess.run(accuracy,\n","  #                        feed_dict={X: x_test.reshape(len(x_test), -1),\n","  #                                  Y: np.eye(10)[y_test].reshape(len(y_test),-1)}))\n","  print(\"Accuracy:\" , accuracy.eval({X : x_test.reshape(len(x_test),-1),\n","                                     Y : np.eye(10)[y_test].reshape(len(y_test),-1)}))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(?, 3072) (?, 10)\n","(3072, 512) (?, 512)\n","(512, 512) (?, 512)\n","(512, 256) (?, 256)\n","(256, 256) (?, 256)\n","Epoch: 0001 Avg. cost = 2.208\n","Epoch: 0002 Avg. cost = 2.022\n","Epoch: 0003 Avg. cost = 1.906\n","Epoch: 0004 Avg. cost = 1.829\n","Epoch: 0005 Avg. cost = 1.763\n","Epoch: 0006 Avg. cost = 1.735\n","Epoch: 0007 Avg. cost = 1.685\n","Epoch: 0008 Avg. cost = 1.677\n","Epoch: 0009 Avg. cost = 1.625\n","Epoch: 0010 Avg. cost = 1.595\n","Epoch: 0011 Avg. cost = 1.581\n","Epoch: 0012 Avg. cost = 1.547\n","Epoch: 0013 Avg. cost = 1.519\n","Epoch: 0014 Avg. cost = 1.509\n","Epoch: 0015 Avg. cost = 1.478\n","Epoch: 0016 Avg. cost = 1.432\n","Epoch: 0017 Avg. cost = 1.439\n","Epoch: 0018 Avg. cost = 1.418\n","Epoch: 0019 Avg. cost = 1.396\n","Epoch: 0020 Avg. cost = 1.368\n","Epoch: 0021 Avg. cost = 1.377\n","Epoch: 0022 Avg. cost = 1.361\n","Epoch: 0023 Avg. cost = 1.337\n","Epoch: 0024 Avg. cost = 1.299\n","Epoch: 0025 Avg. cost = 1.327\n","Epoch: 0026 Avg. cost = 1.283\n","Epoch: 0027 Avg. cost = 1.256\n","Epoch: 0028 Avg. cost = 1.220\n","Epoch: 0029 Avg. cost = 1.222\n","Epoch: 0030 Avg. cost = 1.227\n","Epoch: 0031 Avg. cost = 1.213\n","Epoch: 0032 Avg. cost = 1.182\n","Epoch: 0033 Avg. cost = 1.168\n","Epoch: 0034 Avg. cost = 1.177\n","Epoch: 0035 Avg. cost = 1.147\n","Epoch: 0036 Avg. cost = 1.137\n","Epoch: 0037 Avg. cost = 1.099\n","Epoch: 0038 Avg. cost = 1.067\n","Epoch: 0039 Avg. cost = 1.069\n","Epoch: 0040 Avg. cost = 1.066\n","Epoch: 0041 Avg. cost = 1.066\n","Epoch: 0042 Avg. cost = 1.012\n","Epoch: 0043 Avg. cost = 1.012\n","Epoch: 0044 Avg. cost = 0.985\n","Epoch: 0045 Avg. cost = 0.970\n","Epoch: 0046 Avg. cost = 0.950\n","Epoch: 0047 Avg. cost = 0.978\n","Epoch: 0048 Avg. cost = 0.937\n","Epoch: 0049 Avg. cost = 0.886\n","Epoch: 0050 Avg. cost = 0.921\n","Epoch: 0051 Avg. cost = 0.875\n","Epoch: 0052 Avg. cost = 0.898\n","Epoch: 0053 Avg. cost = 0.853\n","Epoch: 0054 Avg. cost = 0.846\n","Epoch: 0055 Avg. cost = 0.831\n","Epoch: 0056 Avg. cost = 0.789\n","Epoch: 0057 Avg. cost = 0.840\n","Epoch: 0058 Avg. cost = 0.816\n","Epoch: 0059 Avg. cost = 0.770\n","Epoch: 0060 Avg. cost = 0.746\n","Epoch: 0061 Avg. cost = 0.732\n","Epoch: 0062 Avg. cost = 0.746\n","Epoch: 0063 Avg. cost = 0.717\n","Epoch: 0064 Avg. cost = 0.679\n","Epoch: 0065 Avg. cost = 0.664\n","Epoch: 0066 Avg. cost = 0.659\n","Epoch: 0067 Avg. cost = 0.697\n","Epoch: 0068 Avg. cost = 0.669\n","Epoch: 0069 Avg. cost = 0.632\n","Epoch: 0070 Avg. cost = 0.648\n","Epoch: 0071 Avg. cost = 0.612\n","Epoch: 0072 Avg. cost = 0.561\n","Epoch: 0073 Avg. cost = 0.602\n","Epoch: 0074 Avg. cost = 0.592\n","Epoch: 0075 Avg. cost = 0.604\n","Epoch: 0076 Avg. cost = 0.578\n","Epoch: 0077 Avg. cost = 0.553\n","Epoch: 0078 Avg. cost = 0.529\n","Epoch: 0079 Avg. cost = 0.493\n","Epoch: 0080 Avg. cost = 0.514\n","Epoch: 0081 Avg. cost = 0.492\n","Epoch: 0082 Avg. cost = 0.500\n","Epoch: 0083 Avg. cost = 0.494\n","Epoch: 0084 Avg. cost = 0.469\n","Epoch: 0085 Avg. cost = 0.458\n","Epoch: 0086 Avg. cost = 0.431\n","Epoch: 0087 Avg. cost = 0.492\n","Epoch: 0088 Avg. cost = 0.419\n","Epoch: 0089 Avg. cost = 0.392\n","Epoch: 0090 Avg. cost = 0.393\n","Epoch: 0091 Avg. cost = 0.361\n","Epoch: 0092 Avg. cost = 0.391\n","Epoch: 0093 Avg. cost = 0.378\n","Epoch: 0094 Avg. cost = 0.367\n","Epoch: 0095 Avg. cost = 0.360\n","Epoch: 0096 Avg. cost = 0.347\n","Epoch: 0097 Avg. cost = 0.347\n","Epoch: 0098 Avg. cost = 0.358\n","Epoch: 0099 Avg. cost = 0.367\n","Epoch: 0100 Avg. cost = 0.374\n","최적화 완료!\n","Accuracy: 0.4773\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ez74CJRH5J_5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2d97f759-0143-403e-d9b9-098699a98a44","executionInfo":{"status":"ok","timestamp":1564983857866,"user_tz":-540,"elapsed":106802,"user":{"displayName":"ByoungJu Kim","photoUrl":"https://lh3.googleusercontent.com/-riBzYG_Z9-0/AAAAAAAAAAI/AAAAAAAAADw/GWO6ne1-UCs/s64/photo.jpg","userId":"00703136417474445941"}}},"source":["is_training = True\n","\n","X = tf.placeholder(tf.float32, [None, 32*32*3])\n","Y = tf.placeholder(tf.float32, [None, 10])\n","keep_prob = tf.placeholder(tf.float32)\n","print(X.shape, Y.shape)\n","\n","W1 = tf.Variable(tf.random_normal([3072,512], stddev=0.01))\n","B1 = tf.Variable(tf.random_normal([512], stddev=0.01))\n","L1 = tf.matmul(X,W1)+B1\n","L1_batch = tf.layers.batch_normalization(L1, training=is_training)\n","L1_act = tf.nn.relu(L1_batch)\n","L1_act = tf.nn.dropout(L1_act, keep_prob)\n","print(W1.shape, L1.shape)\n","\n","W2 = tf.Variable(tf.random_normal([512,512], stddev = 0.01))\n","B2 = tf.Variable(tf.random_normal([512], stddev=0.01))\n","L2 = tf.matmul(L1_act,W2)+B2\n","L2_batch = tf.layers.batch_normalization(L2, training=is_training)\n","L2_act = tf.nn.relu(L2_batch)\n","L2_act = tf.nn.dropout(L2_act, keep_prob)\n","print(W2.shape, L2.shape)\n","\n","W3 = tf.Variable(tf.random_normal([512,256], stddev = 0.01))\n","B3 = tf.Variable(tf.random_normal([256], stddev=0.01))\n","L3 = tf.matmul(L2_act,W3)+B3\n","L3_batch = tf.layers.batch_normalization(L3, training=is_training)\n","L3_act = tf.nn.relu(L3_batch)\n","L3_act = tf.nn.dropout(L3_act, keep_prob)\n","print(W3.shape, L3.shape)\n","\n","W4 = tf.Variable(tf.random_normal([256,256], stddev = 0.01))\n","B4 = tf.Variable(tf.random_normal([256], stddev = 0.01))\n","L4 = tf.matmul(L3_act,W4)+B4\n","L4_batch = tf.layers.batch_normalization(L4, training=is_training)\n","L4_act = tf.nn.relu(L4_batch)\n","L4_act = tf.nn.dropout(L4_act, keep_prob)\n","print(W4.shape, L4.shape)\n","\n","W5 = tf.Variable(tf.random_normal([256,10], stddev = 0.01))\n","B5 = tf.Variable(tf.random_normal([10], stddev=0.01))\n","model = tf.matmul(L4, W5)+B5\n","\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n","optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n","\n","init = tf.global_variables_initializer()\n","with tf.Session() as sess:\n","  sess.run(init)\n","  \n","  num_epoch = 100 \n","  batch_size = 2500\n","  total_batch = int(len(x_train)/batch_size)\n","  \n","  for epoch in range(num_epoch):\n","    total_cost = 0\n","    \n","    for i in range(total_batch):\n","      if i == (total_batch-1):\n","        order = list(range(len(x_train)))\n","        import random\n","        random.shuffle(order)\n","        x_train = x_train[order]\n","        y_train = y_train[order]\n","        \n","      batch_xs = x_train[i*batch_size:(i+1)*batch_size].reshape(batch_size, -1)\n","      batch_ys = np.eye(10)[y_train[i*batch_size:(i+1)*batch_size]].reshape(batch_size,-1)\n","      #print(batch_xs.shape)\n","      #print(batch_ys.shape)\n","      \n","      _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})  # keep_prob is 80 percent here\n","      total_cost += cost_val\n","      #print(cost_val)\n","      #print(_)\n","\n","    print('Epoch:', '%04d' % (epoch + 1),\n","          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))   \n","  \n","  print('최적화 완료!')\n","  \n","  is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n","  accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n","  #print('정확도:', sess.run(accuracy,\n","  #                        feed_dict={X: x_test.reshape(len(x_test), -1),\n","  #                                  Y: np.eye(10)[y_test].reshape(len(y_test),-1)}))\n","  print(\"Accuracy:\" , accuracy.eval({X : x_test.reshape(len(x_test),-1),\n","                                     Y : np.eye(10)[y_test].reshape(len(y_test),-1),\n","                                     keep_prob: 1}))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["(?, 3072) (?, 10)\n","(3072, 512) (?, 512)\n","(512, 512) (?, 512)\n","(512, 256) (?, 256)\n","(256, 256) (?, 256)\n","Epoch: 0001 Avg. cost = 1.916\n","Epoch: 0002 Avg. cost = 1.579\n","Epoch: 0003 Avg. cost = 1.453\n","Epoch: 0004 Avg. cost = 1.369\n","Epoch: 0005 Avg. cost = 1.302\n","Epoch: 0006 Avg. cost = 1.248\n","Epoch: 0007 Avg. cost = 1.208\n","Epoch: 0008 Avg. cost = 1.164\n","Epoch: 0009 Avg. cost = 1.140\n","Epoch: 0010 Avg. cost = 1.097\n","Epoch: 0011 Avg. cost = 1.057\n","Epoch: 0012 Avg. cost = 1.025\n","Epoch: 0013 Avg. cost = 0.994\n","Epoch: 0014 Avg. cost = 0.972\n","Epoch: 0015 Avg. cost = 0.936\n","Epoch: 0016 Avg. cost = 0.911\n","Epoch: 0017 Avg. cost = 0.887\n","Epoch: 0018 Avg. cost = 0.863\n","Epoch: 0019 Avg. cost = 0.841\n","Epoch: 0020 Avg. cost = 0.820\n","Epoch: 0021 Avg. cost = 0.799\n","Epoch: 0022 Avg. cost = 0.761\n","Epoch: 0023 Avg. cost = 0.755\n","Epoch: 0024 Avg. cost = 0.734\n","Epoch: 0025 Avg. cost = 0.721\n","Epoch: 0026 Avg. cost = 0.694\n","Epoch: 0027 Avg. cost = 0.679\n","Epoch: 0028 Avg. cost = 0.663\n","Epoch: 0029 Avg. cost = 0.635\n","Epoch: 0030 Avg. cost = 0.634\n","Epoch: 0031 Avg. cost = 0.602\n","Epoch: 0032 Avg. cost = 0.588\n","Epoch: 0033 Avg. cost = 0.575\n","Epoch: 0034 Avg. cost = 0.560\n","Epoch: 0035 Avg. cost = 0.551\n","Epoch: 0036 Avg. cost = 0.528\n","Epoch: 0037 Avg. cost = 0.528\n","Epoch: 0038 Avg. cost = 0.500\n","Epoch: 0039 Avg. cost = 0.490\n","Epoch: 0040 Avg. cost = 0.489\n","Epoch: 0041 Avg. cost = 0.473\n","Epoch: 0042 Avg. cost = 0.458\n","Epoch: 0043 Avg. cost = 0.449\n","Epoch: 0044 Avg. cost = 0.442\n","Epoch: 0045 Avg. cost = 0.426\n","Epoch: 0046 Avg. cost = 0.430\n","Epoch: 0047 Avg. cost = 0.411\n","Epoch: 0048 Avg. cost = 0.409\n","Epoch: 0049 Avg. cost = 0.401\n","Epoch: 0050 Avg. cost = 0.383\n","Epoch: 0051 Avg. cost = 0.386\n","Epoch: 0052 Avg. cost = 0.362\n","Epoch: 0053 Avg. cost = 0.360\n","Epoch: 0054 Avg. cost = 0.361\n","Epoch: 0055 Avg. cost = 0.347\n","Epoch: 0056 Avg. cost = 0.342\n","Epoch: 0057 Avg. cost = 0.335\n","Epoch: 0058 Avg. cost = 0.329\n","Epoch: 0059 Avg. cost = 0.328\n","Epoch: 0060 Avg. cost = 0.322\n","Epoch: 0061 Avg. cost = 0.316\n","Epoch: 0062 Avg. cost = 0.307\n","Epoch: 0063 Avg. cost = 0.302\n","Epoch: 0064 Avg. cost = 0.300\n","Epoch: 0065 Avg. cost = 0.302\n","Epoch: 0066 Avg. cost = 0.292\n","Epoch: 0067 Avg. cost = 0.280\n","Epoch: 0068 Avg. cost = 0.277\n","Epoch: 0069 Avg. cost = 0.273\n","Epoch: 0070 Avg. cost = 0.274\n","Epoch: 0071 Avg. cost = 0.263\n","Epoch: 0072 Avg. cost = 0.259\n","Epoch: 0073 Avg. cost = 0.256\n","Epoch: 0074 Avg. cost = 0.262\n","Epoch: 0075 Avg. cost = 0.254\n","Epoch: 0076 Avg. cost = 0.240\n","Epoch: 0077 Avg. cost = 0.250\n","Epoch: 0078 Avg. cost = 0.246\n","Epoch: 0079 Avg. cost = 0.243\n","Epoch: 0080 Avg. cost = 0.238\n","Epoch: 0081 Avg. cost = 0.230\n","Epoch: 0082 Avg. cost = 0.226\n","Epoch: 0083 Avg. cost = 0.228\n","Epoch: 0084 Avg. cost = 0.219\n","Epoch: 0085 Avg. cost = 0.221\n","Epoch: 0086 Avg. cost = 0.223\n","Epoch: 0087 Avg. cost = 0.222\n","Epoch: 0088 Avg. cost = 0.207\n","Epoch: 0089 Avg. cost = 0.211\n","Epoch: 0090 Avg. cost = 0.208\n","Epoch: 0091 Avg. cost = 0.209\n","Epoch: 0092 Avg. cost = 0.212\n","Epoch: 0093 Avg. cost = 0.205\n","Epoch: 0094 Avg. cost = 0.196\n","Epoch: 0095 Avg. cost = 0.193\n","Epoch: 0096 Avg. cost = 0.192\n","Epoch: 0097 Avg. cost = 0.193\n","Epoch: 0098 Avg. cost = 0.193\n","Epoch: 0099 Avg. cost = 0.191\n","Epoch: 0100 Avg. cost = 0.195\n","최적화 완료!\n","Accuracy: 0.5809\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iy4HwD-rIijd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}